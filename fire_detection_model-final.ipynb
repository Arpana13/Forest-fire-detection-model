{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkKmEBDHcyJp"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # import tensorflow module"
      ],
      "metadata": {
        "id": "08NA6M0Jy-Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define augmentation settings\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0,1]\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "T_r5FR13z6hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = '/content/augmented-images'\n",
        "\n",
        "# Create the save directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory                                         #loading the training dataset\n",
        "(\n",
        "    \"/content/dataset2\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory                                           #loading the testing dataset\n",
        "(\n",
        "    '/content/dataset2',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyPFzns5z_w8",
        "outputId": "13faf2fb-2ea4-41b2-e2ac-8f614854f356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2184 images belonging to 4 classes.\n",
            "Found 2184 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/dataset_mod\" \"/content/dataset2\""
      ],
      "metadata": {
        "id": "5GdiIA1B0F_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Fire-master (2)/Fire-master/8thNov_2nd.h5\")   #loading a pre-trained model"
      ],
      "metadata": {
        "id": "wpD4GwhH0Pse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define a checkpoint callback\n",
        "checkpoint = ModelCheckpoint('best_model.h5',\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             mode='min',\n",
        "                             verbose=1)"
      ],
      "metadata": {
        "id": "WYmgPuxn0zRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "i = 20                                                                                                      # Compiling and training the model\n",
        "model.fit_generator(train_generator, epochs=i, validation_data=test_generator,\n",
        "                   steps_per_epoch=len(train_generator),\n",
        "                   validation_steps=len(test_generator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-mZcV1k03fj",
        "outputId": "783e3e3f-29eb-4719-ac8a-16b2721fbc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6ca4a4a8d093>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, epochs=i, validation_data=test_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "69/69 [==============================] - 91s 906ms/step - loss: 0.1599 - accuracy: 0.9524 - val_loss: 0.0863 - val_accuracy: 0.9766\n",
            "Epoch 2/20\n",
            "69/69 [==============================] - 64s 939ms/step - loss: 0.0854 - accuracy: 0.9707 - val_loss: 0.0769 - val_accuracy: 0.9840\n",
            "Epoch 3/20\n",
            "69/69 [==============================] - 63s 911ms/step - loss: 0.0668 - accuracy: 0.9785 - val_loss: 0.0466 - val_accuracy: 0.9876\n",
            "Epoch 4/20\n",
            "69/69 [==============================] - 62s 904ms/step - loss: 0.0705 - accuracy: 0.9789 - val_loss: 0.0962 - val_accuracy: 0.9771\n",
            "Epoch 5/20\n",
            "69/69 [==============================] - 65s 940ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0398 - val_accuracy: 0.9886\n",
            "Epoch 6/20\n",
            "69/69 [==============================] - 62s 898ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.0557 - val_accuracy: 0.9867\n",
            "Epoch 7/20\n",
            "69/69 [==============================] - 62s 906ms/step - loss: 0.0394 - accuracy: 0.9876 - val_loss: 0.0456 - val_accuracy: 0.9872\n",
            "Epoch 8/20\n",
            "69/69 [==============================] - 63s 913ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.1164 - val_accuracy: 0.9725\n",
            "Epoch 9/20\n",
            "69/69 [==============================] - 64s 939ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 0.2242 - val_accuracy: 0.9583\n",
            "Epoch 10/20\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.0350 - accuracy: 0.9849 - val_loss: 0.0491 - val_accuracy: 0.9876\n",
            "Epoch 11/20\n",
            "69/69 [==============================] - 62s 910ms/step - loss: 0.0524 - accuracy: 0.9858 - val_loss: 4.5001 - val_accuracy: 0.5362\n",
            "Epoch 12/20\n",
            "69/69 [==============================] - 63s 924ms/step - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.9794 - val_accuracy: 0.8036\n",
            "Epoch 13/20\n",
            "69/69 [==============================] - 62s 896ms/step - loss: 0.0599 - accuracy: 0.9849 - val_loss: 1.3943 - val_accuracy: 0.7834\n",
            "Epoch 14/20\n",
            "69/69 [==============================] - 62s 904ms/step - loss: 0.0402 - accuracy: 0.9886 - val_loss: 0.6702 - val_accuracy: 0.8805\n",
            "Epoch 15/20\n",
            "69/69 [==============================] - 64s 928ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.1896 - val_accuracy: 0.9679\n",
            "Epoch 16/20\n",
            "69/69 [==============================] - 63s 906ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.1353 - val_accuracy: 0.9739\n",
            "Epoch 17/20\n",
            "69/69 [==============================] - 62s 895ms/step - loss: 0.0255 - accuracy: 0.9899 - val_loss: 0.3195 - val_accuracy: 0.9313\n",
            "Epoch 18/20\n",
            "69/69 [==============================] - 62s 897ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.2184 - val_accuracy: 0.9373\n",
            "Epoch 19/20\n",
            "69/69 [==============================] - 62s 895ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 0.1064 - val_accuracy: 0.9808\n",
            "Epoch 20/20\n",
            "69/69 [==============================] - 62s 896ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0544 - val_accuracy: 0.9876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d21d0132320>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "dwn_CqU5C3Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "model.save(\"fire_det.h5\")     #Saving the model"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "a9G32--qDHJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_new = tf.keras.models.load_model(\"/content/fire_det.h5\")      #Saving the model for future use"
      ],
      "metadata": {
        "id": "LGJl9uigDl0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os                                                                                               #loading and pre-processing the images\n",
        "\n",
        "def process_image(image_path, IMG_SIZE=224):\n",
        "\n",
        "#     if not os.path.exists(image_path) or os.path.getsize(image_path) == 0:\n",
        "# #         print(f\"Invalid image file: {image_path}\")\n",
        "#         return\n",
        "\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_image(image, channels=3, expand_animations= False)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "    return image\n",
        "images_loc = []"
      ],
      "metadata": {
        "id": "EcOXN506HaME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_loc = []                                                                                         #Defining the image location and labelling the images to test accuracy\n",
        "labels = []\n",
        "for i in os.listdir(\"/content/dataset2/s0\"):\n",
        "    images_loc.append(process_image(\"/content/dataset2/s0\"+\"/\"+i))\n",
        "    labels.append(0)\n",
        "for i in os.listdir(\"/content/dataset2/s1\"):\n",
        "    images_loc.append(process_image(\"/content/dataset2/s1\"+\"/\"+i))\n",
        "    labels.append(1)\n",
        "for i in os.listdir(\"/content/dataset2/s2\"):\n",
        "    images_loc.append(process_image(\"/content/dataset2/s2\"+\"/\"+i))\n",
        "    labels.append(2)\n",
        "for i in os.listdir(\"/content/dataset2/s3\"):\n",
        "    images_loc.append(process_image(\"/content/dataset2/s3\"+\"/\"+i))\n",
        "    labels.append(3)"
      ],
      "metadata": {
        "id": "pA6Xk9HGKoPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                                            #Testing model accuracy\n",
        "images_loc = np.array(images_loc)\n",
        "labels = np.array(labels)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(images_loc, labels, test_size=0.3, random_state = 114)\n",
        "y_preds = model_new.predict(X_test)\n",
        "preds = y_preds.argmax(axis = 1)\n",
        "print(f\"Accuracy\", accuracy_score(np.array(preds), np.array(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rSaLFi2LGpU",
        "outputId": "d1374464-2f42-40c1-ed58-dc344edc3614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 2s 53ms/step\n",
            "Accuracy 0.9862804878048781\n"
          ]
        }
      ]
    }
  ]
}